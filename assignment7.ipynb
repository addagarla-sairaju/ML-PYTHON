{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMIO/Vtf/hJo9fFrDIJ0kOa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/addagarla-sairaju/ML-PYTHON/blob/main/assignment7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries\n",
        "These libraries are used for data handling, preprocessing, modeling, and evaluation."
      ],
      "metadata": {
        "id": "HKbMLcKFRG9F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9mAy4nESK5IP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load and Analyze the Dataset\n",
        "This part loads the dataset and provides an overview of its structure and contents"
      ],
      "metadata": {
        "id": "vbkKj3lARNPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/amazon_delivery.csv'\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "print(\"Dataset Head:\\n\", df.head())\n",
        "print(\"\\nDataset Info:\\n\")\n",
        "df.info()\n",
        "print(\"\\nMissing Values:\\n\", df.isnull().sum())\n",
        "print(\"\\nClass Distribution:\\n\", df.iloc[:, -1].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDyvQG5lRUVB",
        "outputId": "6cb3680e-5699-4552-b0e0-e3947f9186ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Head:\n",
            "         Order_ID  Agent_Age  Agent_Rating  Store_Latitude  Store_Longitude  \\\n",
            "0  ialx566343618         37           4.9       22.745049        75.892471   \n",
            "1  akqg208421122         34           4.5       12.913041        77.683237   \n",
            "2  njpu434582536         23           4.4       12.914264        77.678400   \n",
            "3  rjto796129700         38           4.7       11.003669        76.976494   \n",
            "4  zguw716275638         32           4.6       12.972793        80.249982   \n",
            "\n",
            "   Drop_Latitude  Drop_Longitude  Order_Date Order_Time Pickup_Time  \\\n",
            "0      22.765049       75.912471  2022-03-19   11:30:00    11:45:00   \n",
            "1      13.043041       77.813237  2022-03-25   19:45:00    19:50:00   \n",
            "2      12.924264       77.688400  2022-03-19   08:30:00    08:45:00   \n",
            "3      11.053669       77.026494  2022-04-05   18:00:00    18:10:00   \n",
            "4      13.012793       80.289982  2022-03-26   13:30:00    13:45:00   \n",
            "\n",
            "      Weather  Traffic      Vehicle            Area  Delivery_Time  \\\n",
            "0       Sunny    High   motorcycle           Urban             120   \n",
            "1      Stormy     Jam      scooter   Metropolitian             165   \n",
            "2  Sandstorms     Low   motorcycle           Urban             130   \n",
            "3       Sunny  Medium   motorcycle   Metropolitian             105   \n",
            "4      Cloudy    High      scooter   Metropolitian             150   \n",
            "\n",
            "      Category  \n",
            "0     Clothing  \n",
            "1  Electronics  \n",
            "2       Sports  \n",
            "3    Cosmetics  \n",
            "4         Toys  \n",
            "\n",
            "Dataset Info:\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 43739 entries, 0 to 43738\n",
            "Data columns (total 16 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   Order_ID         43739 non-null  object \n",
            " 1   Agent_Age        43739 non-null  int64  \n",
            " 2   Agent_Rating     43685 non-null  float64\n",
            " 3   Store_Latitude   43739 non-null  float64\n",
            " 4   Store_Longitude  43739 non-null  float64\n",
            " 5   Drop_Latitude    43739 non-null  float64\n",
            " 6   Drop_Longitude   43739 non-null  float64\n",
            " 7   Order_Date       43739 non-null  object \n",
            " 8   Order_Time       43739 non-null  object \n",
            " 9   Pickup_Time      43739 non-null  object \n",
            " 10  Weather          43648 non-null  object \n",
            " 11  Traffic          43739 non-null  object \n",
            " 12  Vehicle          43739 non-null  object \n",
            " 13  Area             43739 non-null  object \n",
            " 14  Delivery_Time    43739 non-null  int64  \n",
            " 15  Category         43739 non-null  object \n",
            "dtypes: float64(5), int64(2), object(9)\n",
            "memory usage: 5.3+ MB\n",
            "\n",
            "Missing Values:\n",
            " Order_ID            0\n",
            "Agent_Age           0\n",
            "Agent_Rating       54\n",
            "Store_Latitude      0\n",
            "Store_Longitude     0\n",
            "Drop_Latitude       0\n",
            "Drop_Longitude      0\n",
            "Order_Date          0\n",
            "Order_Time          0\n",
            "Pickup_Time         0\n",
            "Weather            91\n",
            "Traffic             0\n",
            "Vehicle             0\n",
            "Area                0\n",
            "Delivery_Time       0\n",
            "Category            0\n",
            "dtype: int64\n",
            "\n",
            "Class Distribution:\n",
            " Category\n",
            "Electronics     2849\n",
            "Books           2824\n",
            "Jewelry         2802\n",
            "Toys            2781\n",
            "Skincare        2772\n",
            "Snacks          2770\n",
            "Outdoors        2747\n",
            "Apparel         2726\n",
            "Sports          2719\n",
            "Grocery         2691\n",
            "Pet Supplies    2690\n",
            "Home            2685\n",
            "Cosmetics       2677\n",
            "Kitchen         2673\n",
            "Clothing        2667\n",
            "Shoes           2666\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Preprocessing\n",
        "This section handles missing values, encodes categorical features, scales numerical features, and splits the data."
      ],
      "metadata": {
        "id": "5q4wM1gqRa84"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.fillna(df.median(numeric_only=True), inplace=True)\n",
        "df.fillna(df.mode().iloc[0], inplace=True)\n",
        "label_encoders = {}\n",
        "for col in df.select_dtypes(include='object').columns:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    label_encoders[col] = le\n",
        "X = df.iloc[:, :-1]\n",
        "y = df.iloc[:, -1]\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "eloH0o3yReg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train Models\n",
        "This part defines multiple machine learning models and trains them on the dataset"
      ],
      "metadata": {
        "id": "PAn9aYhwRsAh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models={\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"Naive Bayes\": GaussianNB(),\n",
        "    \"KNN\": KNeighborsClassifier(),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"SVC\": SVC()\n",
        "}\n",
        "results={}\n",
        "for model_name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "    results[model_name]={\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"Precision\": precision,\n",
        "        \"Recall\": recall,\n",
        "        \"F1-Score\": f1\n",
        "    }\n"
      ],
      "metadata": {
        "id": "TmiUeeRVRyaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Results\n",
        "This part displays the performance metrics for each model in a readable format."
      ],
      "metadata": {
        "id": "4I6qm1xOSA7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nPerformance Metrics:\\n\")\n",
        "for model_name, metrics in results.items():\n",
        "    print(f\"{model_name}:\\n\")\n",
        "    for metric, value in metrics.items():\n",
        "        print(f\"  {metric}: {value:.4f}\")\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EC7ZYHGsR9fu",
        "outputId": "e2fb68c0-e8a9-43fa-ab75-66e9591455e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Performance Metrics:\n",
            "\n",
            "Logistic Regression:\n",
            "\n",
            "  Accuracy: 0.1244\n",
            "  Precision: 0.1203\n",
            "  Recall: 0.1244\n",
            "  F1-Score: 0.1093\n",
            "\n",
            "\n",
            "Naive Bayes:\n",
            "\n",
            "  Accuracy: 0.1214\n",
            "  Precision: 0.1213\n",
            "  Recall: 0.1214\n",
            "  F1-Score: 0.1024\n",
            "\n",
            "\n",
            "KNN:\n",
            "\n",
            "  Accuracy: 0.1149\n",
            "  Precision: 0.1237\n",
            "  Recall: 0.1149\n",
            "  F1-Score: 0.1125\n",
            "\n",
            "\n",
            "Decision Tree:\n",
            "\n",
            "  Accuracy: 0.1280\n",
            "  Precision: 0.1279\n",
            "  Recall: 0.1280\n",
            "  F1-Score: 0.1279\n",
            "\n",
            "\n",
            "SVC:\n",
            "\n",
            "  Accuracy: 0.1269\n",
            "  Precision: 0.1243\n",
            "  Recall: 0.1269\n",
            "  F1-Score: 0.1225\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}